{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "composite-crawford",
   "metadata": {},
   "source": [
    "## Ice Temperature (icetemp) Package Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Imports from ice temperature estimation package\n",
    "import icetemp\n",
    "import icetemp.data_io as io\n",
    "import icetemp.model as m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-pharmaceutical",
   "metadata": {},
   "source": [
    "This package is intended to infer the change in temperature from measurements of temperature ($^\\circ$C) and depth (m) off of thermistor provided by the AMANDA and IceCube collaborations. Our baseline hypothesis determines a quadratic relationship between the ice temperature and depth, but we will also consider a linear dependence. \n",
    "\n",
    "We have contructed a generative model to analyze the data which involves uniform priors for each term of the polinomials studied and a normal likelihood to relate the Gaussian uncertainties in one dimension. These uncertaintes or noise sources are considered directly related to the thermistor technical information. \n",
    "___\n",
    "In the case of the straight line fit, we have $ T = f(d) = m \\cdot d + b$ where d is the depth and T is the temperature. For each of the true T values with Gaussian uncertainties, we get that the frequency distribution $p(T_i|d_i,\\sigma_{Ti},m,b)$ for $T_i$ is $$ p(T_i|d_i,\\sigma_{Ti},m,b) = \\frac{1}{\\sqrt{2\\pi \\sigma_T^2}} \\exp \\Big(\\frac{-(T_i - md_i - b)^2}{2\\sigma_T^2}\\Big).$$\n",
    "\n",
    "We have no prior information about the dependence of temperature over depth, and for that reason we shall considera \"Flat\" prior for our parameters. Regarding the intecept we could assume it will be in the expected temperature, at ground level, in the Antarctic, which ranges from -20°C (summer) to -60°C (winter).  We can then define our statistical model as:\n",
    "$$ m \\sim \\text{Uniform}( m^l, m^u) \\rightarrow m \\sim \\text{Uniform}(-\\infty ,\\infty)$$\n",
    "\n",
    "$$ b \\sim \\text{Uniform}( b^l, b^u) \\rightarrow b \\sim \\text{Uniform}(-\\infty ,\\infty)$$ where we define $\\mu_i = m \\cdot d_i + b$\n",
    "\n",
    "$$ T_i \\sim \\text{Normal}(\\mu_i,\\sigma_\\text{T})$$\n",
    "\n",
    "The likelihood of the parameter is given by: \n",
    "$$ \\mathcal{L} \\propto \\prod_i \\frac{1}{\\sqrt{2\\pi \\sigma_T^2}} \\exp \\Big(\\frac{-(y_i - mx_i - b)^2}{2\\sigma_T^2}\\Big) $$\n",
    "___\n",
    "In the case of the quadratic line fit, we have $ T = f(d) = q \\cdot d^2 + m \\cdot d + b$ where d is the depth and T is the temperature. For each of the true T values with Gaussian uncertainties, we get that the frequency distribution $p(T_i|d_i,\\sigma_{Ti},m,b)$ for $T_i$ is $$ p(T_i|d_i,\\sigma_{Ti},m,b) = \\frac{1}{\\sqrt{2\\pi \\sigma_T^2}} \\exp \\Big(\\frac{-(T_i - q d_i^2 - md_i - b)^2}{2\\sigma_T^2}\\Big).$$\n",
    "\n",
    "We have no prior information about the dependence of temperature over depth, and for that reason we shall considera \"Flat\" prior for our parameters. Regarding the intecept we could assume it will be in the expected temperature, at ground level, in the Antarctic, which ranges from -20°C (summer) to -60°C (winter).  We can then define our statistical model as:\n",
    "$$ q \\sim \\text{Uniform}( q^l, q^u) \\rightarrow q \\sim \\text{Uniform}(-\\infty , \\infty)$$\n",
    "\n",
    "$$ m \\sim \\text{Uniform}( m^l, m^u) \\rightarrow m \\sim \\text{Uniform}(-\\infty ,\\infty)$$\n",
    "\n",
    "$$ b \\sim \\text{Uniform}( b^l, b^u) \\rightarrow b \\sim \\text{Uniform}(-\\infty , \\infty)$$ \n",
    "\n",
    "where we define $\\mu_i = q \\cdot d_i^2 + m \\cdot d_i + b$\n",
    "\n",
    "$$ T_i \\sim \\text{Normal}(\\mu_i,\\sigma_\\text{T})$$\n",
    "\n",
    "The likelihood of the parameter is given by: \n",
    "$$ \\mathcal{L} \\propto \\prod_i \\frac{1}{\\sqrt{2\\pi \\sigma_T^2}} \\exp \\Big(\\frac{-(y_i - q x_i^2 - mx_i - b)^2}{2\\sigma_T^2}\\Big) $$\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-tourist",
   "metadata": {},
   "source": [
    "#### Let's take a look at our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some (real) data\n",
    "ex_data = io.load_ice_data(\"icecube_temp.2007.txt\", data_year=2007,temp_errors=0.1, depth_errors=2)\n",
    "print(ex_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-practitioner",
   "metadata": {},
   "source": [
    "Using our object (Pandas DataFrame) we can calculate the likelihood function of our statistical model. Below, the likelihood is calculated for some linear and quadratic test data. The details of how this test data was generated are provided in the `test_data` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model parameters for linear and quadratic fit (used to generate test data)\n",
    "a0_lin, a1_lin = -6.35e1, 1.66e-2\n",
    "a0_quad, a1_quad, a2_quad = -4.66e1, -7.47e-3, 6.18e-6\n",
    "\n",
    "# linear test data\n",
    "test_linear = io.load_ice_data(\"test_data_linear.txt\", data_year=0, temp_errors=0.1, depth_errors=2, data_dir='test_data')\n",
    "test_linear.plot(x='Depth', y='Temperature', kind='scatter', yerr=0.1, color='blue')\n",
    "x = test_linear['Depth'].values\n",
    "print('The likelihood value for the linear model with the test data is {:.2f}'.format(m.calc_linear_likelihood(test_linear, a1_lin, a0_lin)))\n",
    "x.sort()\n",
    "plt.plot(x, a1_lin*x + a0_lin, color='blue', linestyle='dashed')\n",
    "plt.title(\"Linear test data\")\n",
    "\n",
    "# quadratic test data\n",
    "test_quad = io.load_ice_data(\"test_data_quadratic.txt\", data_year=0, temp_errors=0.1, depth_errors=2, data_dir='test_data')\n",
    "test_quad.plot(x='Depth', y='Temperature', kind='scatter', yerr=0.1,color='orange')\n",
    "plt.plot(x, a2_quad*x**2 + a1_quad*x + a0_quad, linestyle='dashed')\n",
    "plt.title(\"Quadratic test data\")\n",
    "print('The likelihood value for the quadrartc model with the test data is {:.2f}'.format(m.calc_quad_likelihood(test_quad, a2_quad, a1_quad, a0_quad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-costs",
   "metadata": {},
   "source": [
    "## Doing some inference on the test data\n",
    "\n",
    "The function `fit_quad()` in `model.py` fits the data to a quadratic function and extracts the relevant parameters and covariance matrix. Let's do some inference on the quadratic test data and see if our parameters agree to a reasonable extent. In this function, only the errors on the temperature are considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, cov_mat = m.fit_quad(test_quad)\n",
    "\n",
    "print(\"Values used to generate data:\")\n",
    "print(\"a = {:.3}\".format(a0_quad))\n",
    "print(\"b = {:.3}\".format(a1_quad))\n",
    "print(\"q = {:.3}\".format(a2_quad))\n",
    "\n",
    "# print formatting function adapted from HW 6 solutions\n",
    "uncertainties = np.sqrt(np.diag(cov_mat))\n",
    "print(\"\\nBest fit values:\")\n",
    "for value, sigma, name in zip(params, uncertainties, 'abq'):\n",
    "    print('{} = {:.3} ± {:.3}'.format(name, value, sigma))\n",
    "\n",
    "test_quad.plot(x='Depth', y='Temperature', kind='scatter', yerr=0.1,color='orange')\n",
    "plt.plot(x, params[2]*x**2 + params[1]*x + params[0], linestyle='dashed', color='red')\n",
    "plt.title(\"Quadratic test data with quadratic fit (parameters inferred)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-europe",
   "metadata": {},
   "source": [
    "Indeed, this simple inference returns the parameters with which we generated the data within the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-electronics",
   "metadata": {},
   "source": [
    "# Inference on test data with MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-azerbaijan",
   "metadata": {},
   "source": [
    "Also in `model.py` is the function `fit_quad_MCMC()`, which fits the data to a quadratic function and extracts the relevant parameters and covariance matrix, this time using `pymc3`, which utilizes MCMC sampling techniques. Again, only the errors on the temperature are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, cov_mat = m.fit_quad_MCMC(test_quad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-basis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-blade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
